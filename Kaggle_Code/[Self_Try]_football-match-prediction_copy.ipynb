{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the Winning Football Team\n",
    "\n",
    "- Sports betting is a 500 billion dollar market (Sydney Herald)\n",
    "\n",
    "- Football is played by 250 million players in over 200 countries (most popular sport globally).\n",
    "- The English Premier League is the most popular domestic team in the world.\n",
    "- Design a predictive model capable of accurately predicting if the home team will win a football match?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discription of Dataset**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A prediction system was built to predict whether a home team will win it's match or not.**\n",
    "\n",
    "Key to results data:\n",
    "\n",
    "- Div = League Division\n",
    "- Date = Match Date (dd/mm/yy)\n",
    "- Time = Time of match kick-off\n",
    "- HomeTeam = Home Team\n",
    "- Away team = Away Team\n",
    "- FTHG and HG = Full Time Home Team Goals\n",
    "- FTAG and AG = Full-Time Away Team Goals\n",
    "- FTR and Res = Full-Time Result (H=Home Win, D=Draw, A=Away Win)\n",
    "- HTHG = Half Time Home Team Goals\n",
    "- HTAG = Half Time Away Team Goals\n",
    "- HTR = Half Time Result (H=Home Win, D=Draw, A=Away Win)\n",
    "\n",
    "Match Statistics (where available)\n",
    "\n",
    "- Attendance = Crowd Attendance\n",
    "- Referee = Match Referee\n",
    "- HS = Home Team Shots\n",
    "- AS = Away Team Shots\n",
    "- HST = Home Team Shots on Target\n",
    "- AST = Away Team Shots on Target\n",
    "- HHW = Home Team Hit Woodwork\n",
    "- AHW = Away Team Hit Woodwork\n",
    "- HC = Home Team Corners\n",
    "- AC = Away Team Corners\n",
    "- HF = Home Team Fouls Committed\n",
    "- AF = Away Team Fouls Committed\n",
    "- HFKC = Home Team Free Kicks Conceded\n",
    "- AFKC = Away Team Free Kicks Conceded\n",
    "- HO = Home Team Offsides\n",
    "- AO = Away Team Offsides\n",
    "- HY = Home Team Yellow Cards\n",
    "- AY = Away Team Yellow Cards\n",
    "  \\*HR = Home Team Red Cards\n",
    "  AR = Away Team Red Cards\n",
    "  HBP = Home Team Bookings Points (10 = yellow, 25 = red)\n",
    "  ABP = Away Team Bookings Points (10 = yellow, 25 = red)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from datetime import datetime as dt\n",
    "import itertools\n",
    "import joblib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from the CSV into a dataframe\n",
    "folder='../Datasets/'\n",
    "raw_data_1 = pd.read_csv(folder +'2000-01.csv')\n",
    "raw_data_2 = pd.read_csv(folder +'2001-02.csv')\n",
    "raw_data_3 = pd.read_csv(folder +'2002-03.csv')\n",
    "raw_data_4 = pd.read_csv(folder +'2003-04.csv')\n",
    "raw_data_5 = pd.read_csv(folder +'2004-05.csv')\n",
    "raw_data_6 = pd.read_csv(folder +'2005-06.csv')\n",
    "raw_data_7 = pd.read_csv(folder +'2006-07.csv')\n",
    "raw_data_8 = pd.read_csv(folder +'2007-08.csv')\n",
    "raw_data_9 = pd.read_csv(folder +'2008-09.csv')\n",
    "raw_data_10 = pd.read_csv(folder +'2009-10.csv')\n",
    "raw_data_11 = pd.read_csv(folder +'2010-11.csv')\n",
    "raw_data_12 = pd.read_csv(folder +'2011-12.csv')\n",
    "raw_data_13 = pd.read_csv(folder +'2012-13.csv')\n",
    "raw_data_14 = pd.read_csv(folder +'2013-14.csv')\n",
    "raw_data_15 = pd.read_csv(folder +'2014-15.csv')\n",
    "raw_data_16 = pd.read_csv(folder +'2015-16.csv')\n",
    "raw_data_17 = pd.read_csv(folder +'2016-17.csv')\n",
    "raw_data_18 = pd.read_csv(folder +'2017-18.csv')\n",
    "raw_data_19 = pd.read_csv(folder +'2018-19.csv')\n",
    "raw_data_20 = pd.read_csv(folder +'2019-20.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Self Implemented Code**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all the columns from all the dataframes\n",
    "\n",
    "dataframes = [raw_data_1, raw_data_2, raw_data_3, raw_data_4, raw_data_5,\n",
    "             raw_data_6, raw_data_7, raw_data_8, raw_data_9, raw_data_10,\n",
    "             raw_data_11, raw_data_12, raw_data_13, raw_data_14, raw_data_15,\n",
    "             raw_data_16, raw_data_17, raw_data_18, raw_data_19, raw_data_20]\n",
    "\n",
    "for df in dataframes:\n",
    "    print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Gets all the statistics related to gameplay\n",
    "                      \n",
    "columns_req = ['Date','HomeTeam','AwayTeam','FTHG','FTAG','FTR']\n",
    "\n",
    "playing_statistics_1 = raw_data_1[columns_req]                      \n",
    "playing_statistics_2 = raw_data_2[columns_req]\n",
    "playing_statistics_3 = raw_data_3[columns_req]\n",
    "playing_statistics_4 = raw_data_4[columns_req]\n",
    "playing_statistics_5 = raw_data_5[columns_req]\n",
    "playing_statistics_6 = raw_data_6[columns_req]\n",
    "playing_statistics_7 = raw_data_7[columns_req]\n",
    "playing_statistics_8 = raw_data_8[columns_req]\n",
    "playing_statistics_9 = raw_data_9[columns_req]\n",
    "playing_statistics_10 = raw_data_10[columns_req]\n",
    "playing_statistics_11 = raw_data_11[columns_req]   \n",
    "playing_statistics_12 = raw_data_12[columns_req]\n",
    "playing_statistics_13 = raw_data_13[columns_req]\n",
    "playing_statistics_14 = raw_data_14[columns_req]\n",
    "playing_statistics_15 = raw_data_15[columns_req]\n",
    "playing_statistics_16 = raw_data_16[columns_req]\n",
    "playing_statistics_17 = raw_data_17[columns_req]\n",
    "playing_statistics_18 = raw_data_18[columns_req]\n",
    "playing_statistics_19 = raw_data_19[columns_req]\n",
    "playing_statistics_20 = raw_data_20[columns_req]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GOALS SCORED AND CONCEDED AT THE END OF MATCHWEEK, ARRANGED BY TEAMS AND MATCHWEEK**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the goals scored agg arranged by teams and matchweek\n",
    "def get_goals_scored(playing_stat):\n",
    "    # Create a dictionary with team names as keys\n",
    "    teams = {}\n",
    "    for i in playing_stat['HomeTeam'].unique():\n",
    "        teams[i] = []\n",
    "    \n",
    "    # the value corresponding to keys is a list containing the match location.\n",
    "    for i in range(len(playing_stat)):\n",
    "        HTGS = playing_stat.iloc[i]['FTHG']\n",
    "        ATGS = playing_stat.iloc[i]['FTAG']\n",
    "        teams[playing_stat.iloc[i].HomeTeam].append(HTGS)\n",
    "        teams[playing_stat.iloc[i].AwayTeam].append(ATGS)\n",
    "    \n",
    "    # Calculate number of matchweeks based on total matches and teams\n",
    "    num_teams = len(playing_stat['HomeTeam'].unique())\n",
    "    matches_per_team = len(teams[list(teams.keys())[0]])\n",
    "    \n",
    "    # Create a dataframe for goals scored where rows are teams and cols are matchweek.\n",
    "    GoalsScored = pd.DataFrame(data=teams, index = [i for i in range(1, matches_per_team + 1)]).T\n",
    "    GoalsScored[0] = 0\n",
    "    # Aggregate to get uptil that point\n",
    "    for i in range(2, matches_per_team + 1):\n",
    "        GoalsScored[i] = GoalsScored[i] + GoalsScored[i-1]\n",
    "    return GoalsScored\n",
    "\n",
    "# Gets the goals conceded agg arranged by teams and matchweek\n",
    "def get_goals_conceded(playing_stat):\n",
    "    # Create a dictionary with team names as keys\n",
    "    teams = {}\n",
    "    for i in playing_stat['HomeTeam'].unique():\n",
    "        teams[i] = []\n",
    "    \n",
    "    # the value corresponding to keys is a list containing the match location.\n",
    "    for i in range(len(playing_stat)):\n",
    "        ATGC = playing_stat.iloc[i]['FTHG']\n",
    "        HTGC = playing_stat.iloc[i]['FTAG']\n",
    "        teams[playing_stat.iloc[i].HomeTeam].append(HTGC)\n",
    "        teams[playing_stat.iloc[i].AwayTeam].append(ATGC)\n",
    "    \n",
    "    # Calculate number of matchweeks based on total matches and teams\n",
    "    num_teams = len(playing_stat['HomeTeam'].unique())\n",
    "    matches_per_team = len(teams[list(teams.keys())[0]])\n",
    "    \n",
    "    # Create a dataframe for goals conceded where rows are teams and cols are matchweek.\n",
    "    GoalsConceded = pd.DataFrame(data=teams, index = [i for i in range(1, matches_per_team + 1)]).T\n",
    "    GoalsConceded[0] = 0\n",
    "    # Aggregate to get uptil that point\n",
    "    for i in range(2, matches_per_team + 1):\n",
    "        GoalsConceded[i] = GoalsConceded[i] + GoalsConceded[i-1]\n",
    "    return GoalsConceded\n",
    "    \n",
    "def get_gss(playing_stat):\n",
    "    GC = get_goals_conceded(playing_stat)\n",
    "    GS = get_goals_scored(playing_stat)\n",
    "   \n",
    "    j = 0\n",
    "    HTGS = []\n",
    "    ATGS = []\n",
    "    HTGC = []\n",
    "    ATGC = []\n",
    "\n",
    "    num_teams = len(playing_stat['HomeTeam'].unique())\n",
    "    matches_per_round = num_teams // 2\n",
    "    total_matches = len(playing_stat)\n",
    "\n",
    "    for i in range(total_matches):\n",
    "        ht = playing_stat.iloc[i].HomeTeam\n",
    "        at = playing_stat.iloc[i].AwayTeam\n",
    "        HTGS.append(GS.loc[ht][j])\n",
    "        ATGS.append(GS.loc[at][j])\n",
    "        HTGC.append(GC.loc[ht][j])\n",
    "        ATGC.append(GC.loc[at][j])\n",
    "        \n",
    "        if ((i + 1) % matches_per_round) == 0:\n",
    "            j = j + 1\n",
    "        \n",
    "    playing_stat['HTGS'] = HTGS\n",
    "    playing_stat['ATGS'] = ATGS\n",
    "    playing_stat['HTGC'] = HTGC\n",
    "    playing_stat['ATGC'] = ATGC\n",
    "    \n",
    "    return playing_stat\n",
    "\n",
    "# Apply to each dataset\n",
    "playing_statistics_1 = get_gss(playing_statistics_1)\n",
    "playing_statistics_2 = get_gss(playing_statistics_2)\n",
    "playing_statistics_3 = get_gss(playing_statistics_3)\n",
    "playing_statistics_4 = get_gss(playing_statistics_4)\n",
    "playing_statistics_5 = get_gss(playing_statistics_5)\n",
    "playing_statistics_6 = get_gss(playing_statistics_6)\n",
    "playing_statistics_7 = get_gss(playing_statistics_7)\n",
    "playing_statistics_8 = get_gss(playing_statistics_8)\n",
    "playing_statistics_9 = get_gss(playing_statistics_9)\n",
    "playing_statistics_10 = get_gss(playing_statistics_10)\n",
    "playing_statistics_11 = get_gss(playing_statistics_11)\n",
    "playing_statistics_12 = get_gss(playing_statistics_12)\n",
    "playing_statistics_13 = get_gss(playing_statistics_13)\n",
    "playing_statistics_14 = get_gss(playing_statistics_14)\n",
    "playing_statistics_15 = get_gss(playing_statistics_15)\n",
    "playing_statistics_16 = get_gss(playing_statistics_16)\n",
    "playing_statistics_17 = get_gss(playing_statistics_17)\n",
    "playing_statistics_18 = get_gss(playing_statistics_18)\n",
    "playing_statistics_19 = get_gss(playing_statistics_19)\n",
    "playing_statistics_20 = get_gss(playing_statistics_20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GET RESPECTIVE POINTS**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_points(result):\n",
    "    if result == 'W':\n",
    "        return 3\n",
    "    elif result == 'D':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "\n",
    "def get_cuml_points(matchres):\n",
    "    matchres_points = matchres.applymap(get_points)\n",
    "    # Get the actual number of columns (matchweeks) in the data\n",
    "    num_matchweeks = len(matchres.columns)\n",
    "    for i in range(2, num_matchweeks + 1):\n",
    "        matchres_points[i] = matchres_points[i] + matchres_points[i-1]\n",
    "    \n",
    "    # Get the number of teams from the matchres DataFrame\n",
    "    num_teams = len(matchres)\n",
    "    matchres_points.insert(column=0, loc=0, value=[0 for i in range(num_teams)])\n",
    "    return matchres_points\n",
    "def get_matchres(playing_stat):\n",
    "    # Create a dictionary with team names as keys\n",
    "    teams = {}\n",
    "    for i in playing_stat['HomeTeam'].unique():\n",
    "        teams[i] = []\n",
    "\n",
    "    # the value corresponding to keys is a list containing the match result\n",
    "    for i in range(len(playing_stat)):\n",
    "        if playing_stat.iloc[i].FTR == 'H':\n",
    "            teams[playing_stat.iloc[i].HomeTeam].append('W')\n",
    "            teams[playing_stat.iloc[i].AwayTeam].append('L')\n",
    "        elif playing_stat.iloc[i].FTR == 'A':\n",
    "            teams[playing_stat.iloc[i].AwayTeam].append('W')\n",
    "            teams[playing_stat.iloc[i].HomeTeam].append('L')\n",
    "        else:\n",
    "            teams[playing_stat.iloc[i].AwayTeam].append('D')\n",
    "            teams[playing_stat.iloc[i].HomeTeam].append('D')\n",
    "    \n",
    "    # Calculate the actual number of matchweeks based on matches per team\n",
    "    num_teams = len(playing_stat['HomeTeam'].unique())\n",
    "    matches_per_team = len(teams[list(teams.keys())[0]])\n",
    "    \n",
    "    # Create a dataframe for match results where rows are teams and cols are matchweek\n",
    "    matchres = pd.DataFrame(data=teams, index=[i for i in range(1, matches_per_team + 1)]).T\n",
    "    return matchres\n",
    "def get_agg_points(playing_stat):\n",
    "    matchres = get_matchres(playing_stat)\n",
    "    cum_pts = get_cuml_points(matchres)\n",
    "    HTP = []\n",
    "    ATP = []\n",
    "    j = 0\n",
    "    \n",
    "    # Calculate matches per round dynamically\n",
    "    num_teams = len(playing_stat['HomeTeam'].unique())\n",
    "    matches_per_round = num_teams // 2\n",
    "    total_matches = len(playing_stat)\n",
    "    \n",
    "    for i in range(total_matches):\n",
    "        ht = playing_stat.iloc[i].HomeTeam\n",
    "        at = playing_stat.iloc[i].AwayTeam\n",
    "        HTP.append(cum_pts.loc[ht][j])\n",
    "        ATP.append(cum_pts.loc[at][j])\n",
    "\n",
    "        if ((i + 1) % matches_per_round) == 0:\n",
    "            j = j + 1\n",
    "            \n",
    "    playing_stat['HTP'] = HTP\n",
    "    playing_stat['ATP'] = ATP\n",
    "    return playing_stat\n",
    "    \n",
    "# Apply to each dataset\n",
    "playing_statistics_1 = get_agg_points(playing_statistics_1)\n",
    "playing_statistics_2 = get_agg_points(playing_statistics_2)\n",
    "playing_statistics_3 = get_agg_points(playing_statistics_3)\n",
    "playing_statistics_4 = get_agg_points(playing_statistics_4)\n",
    "playing_statistics_5 = get_agg_points(playing_statistics_5)\n",
    "playing_statistics_6 = get_agg_points(playing_statistics_6)\n",
    "playing_statistics_7 = get_agg_points(playing_statistics_7)\n",
    "playing_statistics_8 = get_agg_points(playing_statistics_8)\n",
    "playing_statistics_9 = get_agg_points(playing_statistics_9)\n",
    "playing_statistics_10 = get_agg_points(playing_statistics_10)\n",
    "playing_statistics_11 = get_agg_points(playing_statistics_11)\n",
    "playing_statistics_12 = get_agg_points(playing_statistics_12)\n",
    "playing_statistics_13 = get_agg_points(playing_statistics_13)\n",
    "playing_statistics_14 = get_agg_points(playing_statistics_14)\n",
    "playing_statistics_15 = get_agg_points(playing_statistics_15)\n",
    "playing_statistics_16 = get_agg_points(playing_statistics_16)\n",
    "playing_statistics_17 = get_agg_points(playing_statistics_17)\n",
    "playing_statistics_18 = get_agg_points(playing_statistics_18)\n",
    "playing_statistics_19 = get_agg_points(playing_statistics_19)\n",
    "playing_statistics_20 = get_agg_points(playing_statistics_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cuml_points(matchres):\n",
    "    matchres_points = matchres.applymap(get_points)\n",
    "    for i in range(2,39):\n",
    "        matchres_points[i] = matchres_points[i] + matchres_points[i-1]\n",
    "    \n",
    "    # Get the number of teams from the matchres DataFrame\n",
    "    num_teams = len(matchres)\n",
    "    matchres_points.insert(column=0, loc=0, value=[0 for i in range(num_teams)])\n",
    "    return matchres_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GET TEAM FORM:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_form(playing_stat,num):\n",
    "    form = get_matchres(playing_stat)\n",
    "    form_final = form.copy()\n",
    "    \n",
    "    # Calculate the actual number of matchweeks dynamically\n",
    "    num_teams = len(playing_stat['HomeTeam'].unique())\n",
    "    matches_per_team = len(playing_stat) // num_teams\n",
    "    max_matchweeks = matches_per_team + 1  # +1 because we start from matchweek 1\n",
    "    \n",
    "    for i in range(num, max_matchweeks):\n",
    "        form_final[i] = ''\n",
    "        j = 1\n",
    "        while j <= num:\n",
    "            if (i-j) in form.columns:  # Check if column exists\n",
    "                form_final[i] += form[i-j]\n",
    "            j += 1           \n",
    "    return form_final\n",
    "\n",
    "def add_form(playing_stat,num):\n",
    "    form = get_form(playing_stat,num)\n",
    "    \n",
    "    # Calculate matches per round dynamically\n",
    "    num_teams = len(playing_stat['HomeTeam'].unique())\n",
    "    matches_per_round = num_teams // 2\n",
    "    total_matches = len(playing_stat)\n",
    "    \n",
    "    h = ['M' for i in range(num * matches_per_round)]  # since form is not available for n MW\n",
    "    a = ['M' for i in range(num * matches_per_round)]\n",
    "    \n",
    "    j = num\n",
    "    for i in range((num * matches_per_round), total_matches):\n",
    "        ht = playing_stat.iloc[i].HomeTeam\n",
    "        at = playing_stat.iloc[i].AwayTeam\n",
    "        \n",
    "        past = form.loc[ht][j]               # get past n results\n",
    "        if len(past) >= num:\n",
    "            h.append(past[0])                    # 0 index is most recent (first character)\n",
    "        else:\n",
    "            h.append('M')\n",
    "        \n",
    "        past = form.loc[at][j]               # get past n results.\n",
    "        if len(past) >= num:\n",
    "            a.append(past[0])                   # 0 index is most recent (first character)\n",
    "        else:\n",
    "            a.append('M')\n",
    "        \n",
    "        if ((i + 1) % matches_per_round) == 0:\n",
    "            j = j + 1\n",
    "\n",
    "    playing_stat['HM' + str(num)] = h                 \n",
    "    playing_stat['AM' + str(num)] = a\n",
    "\n",
    "    return playing_stat\n",
    "\n",
    "def add_form_df(playing_statistics):\n",
    "    playing_statistics = add_form(playing_statistics,1)\n",
    "    playing_statistics = add_form(playing_statistics,2)\n",
    "    playing_statistics = add_form(playing_statistics,3)\n",
    "    playing_statistics = add_form(playing_statistics,4)\n",
    "    playing_statistics = add_form(playing_statistics,5)\n",
    "    return playing_statistics    \n",
    "    \n",
    "# Make changes to df\n",
    "playing_statistics_1 = add_form_df(playing_statistics_1)\n",
    "playing_statistics_2 = add_form_df(playing_statistics_2)\n",
    "playing_statistics_3 = add_form_df(playing_statistics_3)\n",
    "playing_statistics_4 = add_form_df(playing_statistics_4)\n",
    "playing_statistics_5 = add_form_df(playing_statistics_5)\n",
    "playing_statistics_6 = add_form_df(playing_statistics_6)\n",
    "playing_statistics_7 = add_form_df(playing_statistics_7)\n",
    "playing_statistics_8 = add_form_df(playing_statistics_8)\n",
    "playing_statistics_9 = add_form_df(playing_statistics_9)\n",
    "playing_statistics_10 = add_form_df(playing_statistics_10)\n",
    "playing_statistics_11 = add_form_df(playing_statistics_11)\n",
    "playing_statistics_12 = add_form_df(playing_statistics_12)\n",
    "playing_statistics_13 = add_form_df(playing_statistics_13)\n",
    "playing_statistics_14 = add_form_df(playing_statistics_14)\n",
    "playing_statistics_15 = add_form_df(playing_statistics_15)\n",
    "playing_statistics_16 = add_form_df(playing_statistics_16)\n",
    "playing_statistics_17 = add_form_df(playing_statistics_17)\n",
    "playing_statistics_18 = add_form_df(playing_statistics_18)\n",
    "playing_statistics_19 = add_form_df(playing_statistics_19)\n",
    "playing_statistics_20 = add_form_df(playing_statistics_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearranging columns\n",
    "cols = ['Date', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR', 'HTGS', 'ATGS', 'HTGC', 'ATGC', 'HTP', 'ATP', 'HM1', 'HM2', 'HM3',\n",
    "        'HM4', 'HM5', 'AM1', 'AM2', 'AM3', 'AM4', 'AM5' ]\n",
    "\n",
    "playing_statistics_1 = playing_statistics_1[cols]\n",
    "playing_statistics_2 = playing_statistics_2[cols]\n",
    "playing_statistics_3 = playing_statistics_3[cols]\n",
    "playing_statistics_4 = playing_statistics_4[cols]\n",
    "playing_statistics_5 = playing_statistics_5[cols]\n",
    "playing_statistics_6 = playing_statistics_6[cols]\n",
    "playing_statistics_7 = playing_statistics_7[cols]\n",
    "playing_statistics_8 = playing_statistics_8[cols]\n",
    "playing_statistics_9 = playing_statistics_9[cols]\n",
    "playing_statistics_10 = playing_statistics_10[cols]\n",
    "playing_statistics_11 = playing_statistics_11[cols]\n",
    "playing_statistics_12 = playing_statistics_12[cols]\n",
    "playing_statistics_13 = playing_statistics_13[cols]\n",
    "playing_statistics_14 = playing_statistics_14[cols]\n",
    "playing_statistics_15 = playing_statistics_15[cols]\n",
    "playing_statistics_16 = playing_statistics_16[cols]\n",
    "playing_statistics_17 = playing_statistics_17[cols]\n",
    "playing_statistics_18 = playing_statistics_18[cols]\n",
    "playing_statistics_19 = playing_statistics_19[cols]\n",
    "playing_statistics_20 = playing_statistics_20[cols]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get MatchWeek:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mw(playing_stat):\n",
    "    j = 1\n",
    "    MatchWeek = []\n",
    "    num_matches = len(playing_stat)\n",
    "    matches_per_week = 10  # Premier League typically has 10 matches per week\n",
    "    \n",
    "    for i in range(num_matches):\n",
    "        MatchWeek.append(j)\n",
    "        if ((i + 1) % matches_per_week) == 0:\n",
    "            j = j + 1\n",
    "    playing_stat['MW'] = MatchWeek\n",
    "    return playing_stat\n",
    "\n",
    "playing_statistics_1 = get_mw(playing_statistics_1)\n",
    "playing_statistics_2 = get_mw(playing_statistics_2)\n",
    "playing_statistics_3 = get_mw(playing_statistics_3)\n",
    "playing_statistics_4 = get_mw(playing_statistics_4)\n",
    "playing_statistics_5 = get_mw(playing_statistics_5)\n",
    "playing_statistics_6 = get_mw(playing_statistics_6)\n",
    "playing_statistics_7 = get_mw(playing_statistics_7)\n",
    "playing_statistics_8 = get_mw(playing_statistics_8)\n",
    "playing_statistics_9 = get_mw(playing_statistics_9)\n",
    "playing_statistics_10 = get_mw(playing_statistics_10)\n",
    "playing_statistics_11 = get_mw(playing_statistics_11)\n",
    "playing_statistics_12 = get_mw(playing_statistics_12)\n",
    "playing_statistics_13 = get_mw(playing_statistics_13)\n",
    "playing_statistics_14 = get_mw(playing_statistics_14)\n",
    "playing_statistics_15 = get_mw(playing_statistics_15)\n",
    "playing_statistics_16 = get_mw(playing_statistics_16)\n",
    "playing_statistics_17 = get_mw(playing_statistics_17)\n",
    "playing_statistics_18 = get_mw(playing_statistics_18)\n",
    "playing_statistics_19 = get_mw(playing_statistics_19)\n",
    "playing_statistics_20 = get_mw(playing_statistics_20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FINAL DATAFRAME**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playing_stat = pd.concat([playing_statistics_1,\n",
    "                          playing_statistics_2,\n",
    "                          playing_statistics_3,\n",
    "                          playing_statistics_4,\n",
    "                          playing_statistics_5,\n",
    "                          playing_statistics_6,\n",
    "                          playing_statistics_7,\n",
    "                          playing_statistics_8,\n",
    "                          playing_statistics_9,\n",
    "                          playing_statistics_10,\n",
    "                          playing_statistics_11,\n",
    "                          playing_statistics_12,\n",
    "                          playing_statistics_13,\n",
    "                          playing_statistics_14,\n",
    "                          playing_statistics_15,\n",
    "                          playing_statistics_16,\n",
    "                          playing_statistics_17,\n",
    "                          playing_statistics_18,\n",
    "                          playing_statistics_19,\n",
    "                          playing_statistics_20\n",
    "                          ], ignore_index=True)\n",
    "\n",
    "\n",
    "# Gets the form points.\n",
    "def get_form_points(string):\n",
    "    sum = 0\n",
    "    for letter in string:\n",
    "        sum += get_points(letter)\n",
    "    return sum\n",
    "\n",
    "playing_stat['HTFormPtsStr'] = playing_stat['HM1'] + playing_stat['HM2'] + playing_stat['HM3'] + playing_stat['HM4'] + playing_stat['HM5']\n",
    "playing_stat['ATFormPtsStr'] = playing_stat['AM1'] + playing_stat['AM2'] + playing_stat['AM3'] + playing_stat['AM4'] + playing_stat['AM5']\n",
    "\n",
    "playing_stat['HTFormPts'] = playing_stat['HTFormPtsStr'].apply(get_form_points)\n",
    "playing_stat['ATFormPts'] = playing_stat['ATFormPtsStr'].apply(get_form_points)\n",
    "\n",
    "# Identify Win/Loss Streaks if any.\n",
    "def get_3game_ws(string):\n",
    "    if string[-3:] == 'WWW':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def get_5game_ws(string):\n",
    "    if string == 'WWWWW':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def get_3game_ls(string):\n",
    "    if string[-3:] == 'LLL':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def get_5game_ls(string):\n",
    "    if string == 'LLLLL':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "playing_stat['HTWinStreak3'] = playing_stat['HTFormPtsStr'].apply(get_3game_ws)\n",
    "playing_stat['HTWinStreak5'] = playing_stat['HTFormPtsStr'].apply(get_5game_ws)\n",
    "playing_stat['HTLossStreak3'] = playing_stat['HTFormPtsStr'].apply(get_3game_ls)\n",
    "playing_stat['HTLossStreak5'] = playing_stat['HTFormPtsStr'].apply(get_5game_ls)\n",
    "\n",
    "playing_stat['ATWinStreak3'] = playing_stat['ATFormPtsStr'].apply(get_3game_ws)\n",
    "playing_stat['ATWinStreak5'] = playing_stat['ATFormPtsStr'].apply(get_5game_ws)\n",
    "playing_stat['ATLossStreak3'] = playing_stat['ATFormPtsStr'].apply(get_3game_ls)\n",
    "playing_stat['ATLossStreak5'] = playing_stat['ATFormPtsStr'].apply(get_5game_ls)\n",
    "\n",
    "playing_stat.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Goal Difference\n",
    "playing_stat['HTGD'] = playing_stat['HTGS'] - playing_stat['HTGC']\n",
    "playing_stat['ATGD'] = playing_stat['ATGS'] - playing_stat['ATGC']\n",
    "\n",
    "# Diff in points\n",
    "playing_stat['DiffPts'] = playing_stat['HTP'] - playing_stat['ATP']\n",
    "playing_stat['DiffFormPts'] = playing_stat['HTFormPts'] - playing_stat['ATFormPts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale DiffPts , DiffFormPts, HTGD, ATGD by Matchweek.\n",
    "cols = ['HTGD','ATGD','DiffPts','DiffFormPts','HTP','ATP']\n",
    "playing_stat.MW = playing_stat.MW.astype(float)\n",
    "\n",
    "for col in cols:\n",
    "    playing_stat[col] = playing_stat[col] / playing_stat.MW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def only_hw(string):\n",
    "    if string == 'H':\n",
    "        return 'H'\n",
    "    else:\n",
    "        return 'NH'\n",
    "    \n",
    "playing_stat['FTR'] = playing_stat.FTR.apply(only_hw)\n",
    "\n",
    "# Testing set (2015-16 season)\n",
    "playing_stat_test = playing_stat[5700:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the final dataset\n",
    "playing_stat.to_csv('Self_Datasets/Football_match_prediction_copy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the test set\n",
    "playing_stat_test.to_csv(\"Self_Datasets/Football_match_prediction_copy_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the final dataset\n",
    "dataset = pd.read_csv('Self_Datasets/Football_match_prediction_copy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Features: Detailed Description\n",
    "\n",
    "### **Basic Match Information**\n",
    "\n",
    "- **Date**: Match date - Essential for temporal analysis and seasonal patterns\n",
    "- **HomeTeam**: Name of the home team - Critical for home advantage analysis\n",
    "- **AwayTeam**: Name of the away team - Used for team-specific performance tracking\n",
    "- **FTHG (Full Time Home Goals)**: Goals scored by home team - Direct match outcome indicator\n",
    "- **FTAG (Full Time Away Goals)**: Goals scored by away team - Direct match outcome indicator\n",
    "- **FTR (Full Time Result)**: Match result (H=Home Win, D=Draw, A=Away Win) - **Target variable** for prediction\n",
    "\n",
    "### **Cumulative Performance Metrics**\n",
    "\n",
    "- **HTGS (Home Team Goals Scored)**: Cumulative goals scored by home team up to current matchweek\n",
    "\n",
    "  - _Derivation_: Running total of all goals scored by the team in previous matches\n",
    "  - _Utility_: Indicates offensive strength and scoring consistency over time\n",
    "\n",
    "- **ATGS (Away Team Goals Scored)**: Cumulative goals scored by away team up to current matchweek\n",
    "\n",
    "  - _Derivation_: Running total of all goals scored by the team in previous matches\n",
    "  - _Utility_: Shows away team's attacking prowess and goal-scoring ability\n",
    "\n",
    "- **HTGC (Home Team Goals Conceded)**: Cumulative goals conceded by home team up to current matchweek\n",
    "\n",
    "  - _Derivation_: Running total of all goals conceded by the team in previous matches\n",
    "  - _Utility_: Reflects defensive stability and ability to prevent goals\n",
    "\n",
    "- **ATGC (Away Team Goals Conceded)**: Cumulative goals conceded by away team up to current matchweek\n",
    "  - _Derivation_: Running total of all goals conceded by the team in previous matches\n",
    "  - _Utility_: Indicates defensive weaknesses and vulnerability\n",
    "\n",
    "### **Points and League Position Indicators**\n",
    "\n",
    "- **HTP (Home Team Points)**: Cumulative league points earned by home team up to current matchweek\n",
    "\n",
    "  - _Derivation_: 3 points for win, 1 for draw, 0 for loss - accumulated over season\n",
    "  - _Utility_: Direct measure of team's overall performance and league standing\n",
    "\n",
    "- **ATP (Away Team Points)**: Cumulative league points earned by away team up to current matchweek\n",
    "  - _Derivation_: Same point system as HTP, accumulated over season\n",
    "  - _Utility_: Shows away team's season performance and competitive strength\n",
    "\n",
    "### **Recent Form Indicators (Last 1-5 Matches)**\n",
    "\n",
    "- **HM1-HM5**: Home team's results in last 1-5 matches (W/D/L)\n",
    "\n",
    "  - _Derivation_: Character strings showing most recent match results\n",
    "  - _Utility_: Captures current momentum, confidence, and short-term performance trends\n",
    "\n",
    "- **AM1-AM5**: Away team's results in last 1-5 matches (W/D/L)\n",
    "  - _Derivation_: Character strings showing most recent match results\n",
    "  - _Utility_: Indicates current form and psychological state of away team\n",
    "\n",
    "### **Temporal Context**\n",
    "\n",
    "- **MW (Match Week)**: Current matchweek number in the season\n",
    "  - _Derivation_: Sequential numbering based on fixture scheduling\n",
    "  - _Utility_: Controls for seasonal effects, fatigue, and experience accumulation\n",
    "\n",
    "### **Advanced Performance Metrics**\n",
    "\n",
    "- **HTGD (Home Team Goal Difference)**: Goals scored minus goals conceded for home team\n",
    "\n",
    "  - _Derivation_: HTGS - HTGC, normalized by matchweek\n",
    "  - _Utility_: Single metric combining offensive and defensive performance\n",
    "\n",
    "- **ATGD (Away Team Goal Difference)**: Goals scored minus goals conceded for away team\n",
    "\n",
    "  - _Derivation_: ATGS - ATGC, normalized by matchweek\n",
    "  - _Utility_: Comprehensive measure of team quality and balance\n",
    "\n",
    "- **DiffPts (Points Difference)**: Difference in accumulated points between teams\n",
    "\n",
    "  - _Derivation_: HTP - ATP, normalized by matchweek\n",
    "  - _Utility_: Direct comparison of team standings and relative strength\n",
    "\n",
    "- **DiffFormPts (Form Points Difference)**: Difference in recent form points\n",
    "  - _Derivation_: HTFormPts - ATFormPts (points from last 5 matches)\n",
    "  - _Utility_: Captures momentum differential and current competitive edge\n",
    "\n",
    "### **Form Analysis Features**\n",
    "\n",
    "- **HTFormPts/ATFormPts**: Points earned from last 5 matches\n",
    "\n",
    "  - _Derivation_: Sum of points from HM1-HM5 and AM1-AM5 respectively\n",
    "  - _Utility_: Quantifies recent performance trend\n",
    "\n",
    "- **Win/Loss Streak Indicators**: Binary flags for 3-game and 5-game streaks\n",
    "  - _Derivation_: Pattern matching on form strings (WWW, WWWWW, LLL, LLLLL)\n",
    "  - _Utility_: Identifies teams in exceptional form (positive or negative momentum)\n",
    "\n",
    "### **Why These Features Are Valuable:**\n",
    "\n",
    "1. **Predictive Power**: Combine historical performance with current form\n",
    "2. **Normalization**: Metrics scaled by matchweek account for season progression\n",
    "3. **Multi-dimensional Analysis**: Cover offense, defense, overall performance, and momentum\n",
    "4. **Home Advantage**: Separate tracking for home/away performance differences\n",
    "5. **Temporal Relevance**: Recent form weighted more heavily than distant past\n",
    "6. **Comparative Analysis**: Direct team-vs-team comparisons (difference metrics)\n",
    "\n",
    "This feature set provides a comprehensive view of team performance, enabling the model to capture both long-term quality and short-term momentum that influence match outcomes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Matrix for dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10)) \n",
    "# Select only numeric columns for correlation matrix\n",
    "numeric_cols = dataset.select_dtypes(include=[np.number])\n",
    "sns.heatmap(numeric_cols.corr(), annot=True)\n",
    "plt.title('Correlation Matrix for Football Match Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POSITIVE CORRELATION: If an increase in feature A leads to increase in feature B, then they are positively correlated. A value 1 means perfect positive correlation.\n",
    "\n",
    "NEGATIVE CORRELATION: If an increase in feature A leads to decrease in feature B, then they are negatively correlated. A value -1 means perfect negative correlation.\n",
    "\n",
    "Now lets say that two features are highly or perfectly correlated, so the increase in one leads to increase in the other. This means that both the features are containing highly similar information and there is very little or no variance in information. This is known as MultiColinearity as both of them contains almost the same information.\n",
    "\n",
    "So do you think we should use both of them as one of them is redundant. While making or training models, we should try to eliminate redundant features as it reduces training time and many such advantages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove few columns\n",
    "# Removing these columns for the following reasons:\n",
    "# 1. Non-predictive identifiers: 'Date', 'HomeTeam', 'AwayTeam' - These are categorical identifiers that don't contribute to predictive modeling\n",
    "# 2. Target leakage: 'FTHG', 'FTAG' - Full time goals are outcomes of the match, using them would leak future information\n",
    "# 3. Redundant cumulative stats: 'HTGS', 'ATGS', 'HTGC', 'ATGC' - These are already incorporated into goal difference metrics\n",
    "# 4. Less informative form indicators: 'HM4', 'HM5', 'AM4', 'AM5' - Longer-term form is less predictive than recent form (HM1-HM3)\n",
    "# 5. Temporal identifier: 'MW' - Matchweek number doesn't directly predict outcomes\n",
    "# 6. Intermediate calculations: 'HTFormPtsStr', 'ATFormPtsStr' - String representations used to calculate numerical form points\n",
    "# 7. Redundant form metrics: 'HTFormPts', 'ATFormPts' - Individual team form points are less informative than the difference (DiffFormPts)\n",
    "# 8. Low-impact streak indicators: Win/Loss streak flags for 3 and 5 games - These specific patterns are less predictive\n",
    "# 9. Redundant comparison: 'DiffPts' - This metric is less informative compared to other difference metrics we're keeping\n",
    "# The goal is to reduce dimensionality while retaining the most predictive features for home team win prediction\n",
    "\n",
    "dataset2 = dataset.copy().drop(columns =['Date', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG',\n",
    "  'HTGS', 'ATGS', 'HTGC', 'ATGC',\n",
    "  'HM4', 'HM5','AM4', 'AM5', 'MW', 'HTFormPtsStr',\n",
    "  'ATFormPtsStr', 'HTFormPts', 'ATFormPts', 'HTWinStreak3',\n",
    "  'HTWinStreak5', 'HTLossStreak3', 'HTLossStreak5', 'ATWinStreak3',\n",
    "  'ATWinStreak5', 'ATLossStreak3', 'ATLossStreak5',\n",
    "  'DiffPts'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what is the win rate for the home team?\n",
    "\n",
    "# Total number of matches.\n",
    "n_matches = dataset2.shape[0]\n",
    "\n",
    "# Calculate number of features. -1 because we are saving one as the target variable (win/lose/draw)\n",
    "n_features = dataset2.shape[1] - 1\n",
    "\n",
    "# Calculate matches won by home team.\n",
    "n_homewins = len(dataset2[dataset2.FTR == 'H'])\n",
    "\n",
    "# Calculate win rate for home team.\n",
    "win_rate = (float(n_homewins) / (n_matches)) * 100\n",
    "\n",
    "# Print the results\n",
    "print(\"Total number of matches: {}\".format(n_matches))\n",
    "print (\"Number of features: {}\".format(n_features))\n",
    "print( \"Number of matches won by home team: {}\".format(n_homewins))\n",
    "print (\"Win rate of home team: {:.2f}%\".format(win_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising distribution of data\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "#the scatter matrix is plotting each of the columns specified against each other column.\n",
    "#You would have observed that the diagonal graph is defined as a histogram, which means that in the \n",
    "#section of the plot matrix where the variable is against itself, a histogram is plotted.\n",
    "\n",
    "#Scatter plots show how much one variable is affected by another. \n",
    "#The relationship between two variables is called their correlation\n",
    "#negative vs positive correlation\n",
    "\n",
    "#HTGD - Home team goal difference\n",
    "#ATGD - away team goal difference\n",
    "#HTP - Home team points\n",
    "#ATP - Away team points\n",
    "#DiffFormPts Diff in points\n",
    "#DiffLP - Differnece in last years prediction\n",
    "\n",
    "scatter_matrix(dataset2[['HTGD','ATGD','HTP','ATP','DiffFormPts']], figsize=(15,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate into feature set and target variable\n",
    "#FTR = Full Time Result (H=Home Win, D=Draw, A=Away Win)\n",
    "X_all = dataset2.drop(columns=['FTR'])\n",
    "y_all = dataset2['FTR']\n",
    "\n",
    "# Standardising the data.\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "#Center to the mean and component wise scale to unit variance.\n",
    "cols = ['HTGD','ATGD','HTP','ATP']\n",
    "for col in cols:\n",
    "    X_all[col] = scale(X_all[col])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#last 3 wins for both sides\n",
    "X_all.HM1 = X_all.HM1.astype('str')\n",
    "X_all.HM2 = X_all.HM2.astype('str')\n",
    "X_all.HM3 = X_all.HM3.astype('str')\n",
    "X_all.AM1 = X_all.AM1.astype('str')\n",
    "X_all.AM2 = X_all.AM2.astype('str')\n",
    "X_all.AM3 = X_all.AM3.astype('str')\n",
    "\n",
    "#we want continous vars that are integers for our input data, so lets remove any categorical vars\n",
    "def preprocess_features(X):\n",
    "    ''' Preprocesses the football data and converts catagorical variables into dummy variables. '''\n",
    "    \n",
    "    # Initialize new output DataFrame\n",
    "    output = pd.DataFrame(index = X.index)\n",
    "\n",
    "    # Investigate each feature column for the data\n",
    "    for col, col_data in X.items():\n",
    "\n",
    "        # If data type is categorical, convert to dummy variables\n",
    "        if col_data.dtype == object:\n",
    "            col_data = pd.get_dummies(col_data, prefix = col)\n",
    "                    \n",
    "        # Collect the revised columns\n",
    "        output = output.join(col_data)\n",
    "    \n",
    "    return output\n",
    "\n",
    "X_all = preprocess_features(X_all)\n",
    "print (\"Processed feature columns ({} total features):\\n{}\".format(len(X_all.columns), list(X_all.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Feature Analysis for Football Match Prediction\n",
    "\n",
    "### **1. Unnamed: 0**\n",
    "\n",
    "- **Description**: Index column from the original dataset\n",
    "- **Derivation**: Automatically generated when saving/loading CSV files\n",
    "- **Significance**: No predictive value - should be removed in preprocessing\n",
    "- **Impact on Target**: None - purely administrative\n",
    "\n",
    "---\n",
    "\n",
    "### **2. HTP (Home Team Points)**\n",
    "\n",
    "- **Description**: Cumulative league points earned by the home team up to the current matchweek\n",
    "- **Derivation**:\n",
    "  ```\n",
    "  Points System: Win = 3 points, Draw = 1 point, Loss = 0 points\n",
    "  HTP = Sum of all points earned in previous matches this season\n",
    "  Normalized by matchweek: HTP = Total Points / Current Matchweek\n",
    "  ```\n",
    "- **Significance**: Direct measure of team quality and season performance\n",
    "- **Impact on Target**: **High Positive Correlation** - Teams with more points are more likely to win\n",
    "- **Why Important**: Reflects overall team strength, consistency, and current league position\n",
    "\n",
    "---\n",
    "\n",
    "### **3. ATP (Away Team Points)**\n",
    "\n",
    "- **Description**: Cumulative league points earned by the away team up to the current matchweek\n",
    "- **Derivation**: Same as HTP but for the away team, normalized by matchweek\n",
    "- **Significance**: Measures away team's season performance and competitive level\n",
    "- **Impact on Target**: **High Negative Correlation** - Higher away team points reduce home team win probability\n",
    "- **Why Important**: Essential for comparative analysis between competing teams\n",
    "\n",
    "---\n",
    "\n",
    "### **4-7. HM1 Form Indicators (Home Team Last Match)**\n",
    "\n",
    "**HM1_D, HM1_L, HM1_M, HM1_W** (One-hot encoded)\n",
    "\n",
    "- **Description**: Result of home team's most recent match\n",
    "- **Derivation**:\n",
    "  ```\n",
    "  Original: Single character (W/D/L/M)\n",
    "  Transformed: Binary indicators via get_dummies()\n",
    "  HM1_W = 1 if last match was Won, 0 otherwise\n",
    "  HM1_D = 1 if last match was Draw, 0 otherwise\n",
    "  HM1_L = 1 if last match was Lost, 0 otherwise\n",
    "  HM1_M = 1 if no data available (Missing), 0 otherwise\n",
    "  ```\n",
    "- **Significance**: **Immediate momentum indicator** - most recent form is highly predictive\n",
    "- **Impact on Target**:\n",
    "  - **HM1_W**: Strong positive correlation with home wins\n",
    "  - **HM1_L**: Strong negative correlation with home wins\n",
    "  - **HM1_D**: Moderate impact\n",
    "- **Why Important**: Recent performance strongly influences confidence, morale, and tactical approach\n",
    "\n",
    "---\n",
    "\n",
    "### **8-11. HM2 Form Indicators (Home Team 2nd Last Match)**\n",
    "\n",
    "**HM2_D, HM2_L, HM2_M, HM2_W**\n",
    "\n",
    "- **Description**: Result of home team's second most recent match\n",
    "- **Derivation**: Same one-hot encoding as HM1, but for match played 2 games ago\n",
    "- **Significance**: Secondary momentum indicator with declining influence\n",
    "- **Impact on Target**: Moderate correlation, less than HM1 but still significant\n",
    "- **Why Important**: Helps identify short-term trends and consistency patterns\n",
    "\n",
    "---\n",
    "\n",
    "### **12-15. HM3 Form Indicators (Home Team 3rd Last Match)**\n",
    "\n",
    "**HM3_D, HM3_L, HM3_M, HM3_W**\n",
    "\n",
    "- **Description**: Result of home team's third most recent match\n",
    "- **Derivation**: One-hot encoded result from 3 matches ago\n",
    "- **Significance**: Tertiary momentum indicator with further reduced influence\n",
    "- **Impact on Target**: Weak to moderate correlation\n",
    "- **Why Important**: Provides context for form trends but less predictive weight\n",
    "\n",
    "---\n",
    "\n",
    "### **16-19. AM1 Form Indicators (Away Team Last Match)**\n",
    "\n",
    "**AM1_D, AM1_L, AM1_M, AM1_W**\n",
    "\n",
    "- **Description**: Result of away team's most recent match\n",
    "- **Derivation**: Same encoding as HM1 but for away team\n",
    "- **Significance**: Critical for assessing away team momentum\n",
    "- **Impact on Target**:\n",
    "  - **AM1_W**: Strong negative correlation with home wins\n",
    "  - **AM1_L**: Strong positive correlation with home wins\n",
    "- **Why Important**: Away team form significantly impacts match dynamics\n",
    "\n",
    "---\n",
    "\n",
    "### **20-23. AM2 Form Indicators (Away Team 2nd Last Match)**\n",
    "\n",
    "**AM2_D, AM2_L, AM2_M, AM2_W**\n",
    "\n",
    "- **Description**: Away team's second most recent match result\n",
    "- **Derivation**: One-hot encoded result from 2 matches ago\n",
    "- **Significance**: Secondary away team momentum indicator\n",
    "- **Impact on Target**: Moderate negative correlation with home wins\n",
    "\n",
    "---\n",
    "\n",
    "### **24-27. AM3 Form Indicators (Away Team 3rd Last Match)**\n",
    "\n",
    "**AM3_D, AM3_L, AM3_M, AM3_W**\n",
    "\n",
    "- **Description**: Away team's third most recent match result\n",
    "- **Derivation**: One-hot encoded result from 3 matches ago\n",
    "- **Significance**: Tertiary away team momentum indicator\n",
    "- **Impact on Target**: Weak correlation with home wins\n",
    "\n",
    "---\n",
    "\n",
    "### **28. HTGD (Home Team Goal Difference)**\n",
    "\n",
    "- **Description**: Home team's goal difference normalized by matchweek\n",
    "- **Derivation**:\n",
    "  ```\n",
    "  HTGD = (Cumulative Goals Scored - Cumulative Goals Conceded) / Matchweek\n",
    "  Raw Calculation: HTGS - HTGC\n",
    "  Normalization accounts for seasonal progression\n",
    "  ```\n",
    "- **Combined Features**:\n",
    "  - **HTGS** (Home Team Goals Scored): Cumulative attacking output\n",
    "  - **HTGC** (Home Team Goals Conceded): Cumulative defensive performance\n",
    "- **Significance**: **Single metric combining offensive and defensive capability**\n",
    "- **Impact on Target**: **Very High Positive Correlation** - Teams with better goal difference win more\n",
    "- **Why Critical**:\n",
    "  - Balances attack and defense\n",
    "  - Indicates overall team quality\n",
    "  - Strong predictor of match outcomes\n",
    "  - Accounts for both scoring ability and defensive solidity\n",
    "\n",
    "---\n",
    "\n",
    "### **29. ATGD (Away Team Goal Difference)**\n",
    "\n",
    "- **Description**: Away team's goal difference normalized by matchweek\n",
    "- **Derivation**: Same as HTGD but for away team: (ATGS - ATGC) / Matchweek\n",
    "- **Combined Features**: ATGS (Away Goals Scored) + ATGC (Away Goals Conceded)\n",
    "- **Significance**: Comprehensive measure of away team quality\n",
    "- **Impact on Target**: **Very High Negative Correlation** - Better away team goal difference reduces home win probability\n",
    "- **Why Critical**: Essential counterpart to HTGD for team comparison\n",
    "\n",
    "---\n",
    "\n",
    "### **30. DiffFormPts (Form Points Difference)**\n",
    "\n",
    "- **Description**: Difference between home and away team form points from last 5 matches\n",
    "- **Derivation**:\n",
    "  ```\n",
    "  HTFormPts = Sum of points from HM1-HM5 (W=3, D=1, L=0)\n",
    "  ATFormPts = Sum of points from AM1-AM5 (W=3, D=1, L=0)\n",
    "  DiffFormPts = HTFormPts - ATFormPts\n",
    "  Range: -15 to +15 points\n",
    "  ```\n",
    "- **Combined Features**: All recent form indicators (HM1-HM5, AM1-AM5)\n",
    "- **Significance**: **Direct comparison of recent momentum between teams**\n",
    "- **Impact on Target**: **High Positive Correlation**\n",
    "  - Positive values favor home team wins\n",
    "  - Negative values favor away team/draw outcomes\n",
    "- **Why Important**:\n",
    "  - Captures relative momentum\n",
    "  - More predictive than individual team form\n",
    "  - Accounts for psychological factors\n",
    "  - Reflects current competitive edge\n",
    "\n",
    "---\n",
    "\n",
    "## **Feature Importance Hierarchy**\n",
    "\n",
    "### **Tier 1 - Critical Predictors:**\n",
    "\n",
    "1. **HTGD & ATGD**: Overall team quality measures\n",
    "2. **DiffFormPts**: Recent momentum comparison\n",
    "3. **HTP & ATP**: Season-long performance indicators\n",
    "\n",
    "### **Tier 2 - Important Indicators:**\n",
    "\n",
    "4. **HM1_W, HM1_L**: Immediate home team form\n",
    "5. **AM1_W, AM1_L**: Immediate away team form\n",
    "\n",
    "### **Tier 3 - Supporting Features:**\n",
    "\n",
    "6. **HM2, AM2 indicators**: Secondary form context\n",
    "7. **HM3, AM3 indicators**: Tertiary form background\n",
    "\n",
    "### **Tier 4 - Remove:**\n",
    "\n",
    "8. **Unnamed: 0**: No predictive value\n",
    "\n",
    "---\n",
    "\n",
    "## **Key Insights for Model Performance**\n",
    "\n",
    "1. **Goal Difference** (HTGD, ATGD) are the strongest predictors because they encapsulate both offensive and defensive capabilities\n",
    "\n",
    "2. **Recent Form** (especially last match) has high predictive power due to psychological momentum effects\n",
    "\n",
    "3. **Form Difference** (DiffFormPts) is more informative than individual team form because it provides direct comparison\n",
    "\n",
    "4. **Seasonal Points** (HTP, ATP) provide long-term context but are less dynamic than form-based features\n",
    "\n",
    "5. **One-hot Encoding** of categorical form variables allows the model to capture non-linear relationships between different match outcomes\n",
    "\n",
    "This feature set effectively balances **historical performance** (points, goal difference) with **current momentum** (recent form), providing comprehensive team assessment for accurate match prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spliting the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Shuffle and split the dataset into training and testing set.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, \n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state = 2,\n",
    "                                                    stratify = y_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying the Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Logistic Regression to the Training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "cm = confusion_matrix(y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cm, annot=True,fmt='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying the SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting the SVM to the training set\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'rbf',random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting result\n",
    "Y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cm, annot=True, fmt='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying the RandomForest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting the RANDOM FOREST to the training set\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "classifier = RandomForestClassifier(criterion='gini', \n",
    "                             n_estimators=700,\n",
    "                             min_samples_split=10,\n",
    "                             min_samples_leaf=1,\n",
    "                             max_features='sqrt',\n",
    "                             oob_score=True,\n",
    "                             random_state=1,\n",
    "                             n_jobs=-1)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting result\n",
    "Y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cm, annot=True, fmt='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying the XGBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install XGBoost if not already installed\n",
    "# %pip install xgboost\n",
    "\n",
    "# Fitting XGBoost to the Training set\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode target labels to numeric values\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "classifier = XGBClassifier(seed=82)\n",
    "classifier.fit(X_train, y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "Y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# Decode the predictions back to original labels\n",
    "Y_pred_decoded = label_encoder.inverse_transform(Y_pred)\n",
    "cm = confusion_matrix(y_test, Y_pred_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cm, annot=True,fmt='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, Y_pred_decoded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clearly XGBoost seems like the best model as it has the highest F1 score and accuracy score on the test set.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning the parameters of XGBoost.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import 'GridSearchCV' and 'make_scorer'\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "import xgboost as xgb\n",
    "\n",
    "# TODO: Create the parameters list you wish to tune\n",
    "parameters = { 'learning_rate' : [0.1],\n",
    "               'n_estimators' : [40],\n",
    "               'max_depth': [3],\n",
    "               'min_child_weight': [3],\n",
    "               'gamma':[0.4],\n",
    "               'subsample' : [0.8],\n",
    "               'colsample_bytree' : [0.8],\n",
    "               'scale_pos_weight' : [1],\n",
    "               'reg_alpha':[1e-5]\n",
    "             }  \n",
    "\n",
    "def predict_labels(clf, features, target):\n",
    "    ''' Makes predictions using a fit classifier based on F1 score. '''\n",
    "\n",
    "    y_pred = clf.predict(features)\n",
    "    \n",
    "    return f1_score(target, y_pred, pos_label=0), sum(target == y_pred) / float(len(y_pred))\n",
    "\n",
    "# TODO: Initialize the classifier\n",
    "clf = xgb.XGBClassifier(seed=2)\n",
    "\n",
    "# TODO: Make an f1 scoring function using 'make_scorer' \n",
    "f1_scorer = make_scorer(f1_score, pos_label=0)  # 0 corresponds to 'H' in encoded labels\n",
    "\n",
    "# TODO: Perform grid search on the classifier using the f1_scorer as the scoring method\n",
    "grid_obj = GridSearchCV(clf,\n",
    "                        scoring=f1_scorer,\n",
    "                        param_grid=parameters,\n",
    "                        cv=5)\n",
    "\n",
    "# TODO: Fit the grid search object to the training data and find the optimal parameters\n",
    "grid_obj = grid_obj.fit(X_train, y_train_encoded)\n",
    "\n",
    "# Get the estimator\n",
    "clf = grid_obj.best_estimator_\n",
    "print(clf)\n",
    "\n",
    "# Report the final F1 score for training and testing after parameter tuning\n",
    "f1, acc = predict_labels(clf, X_train, y_train_encoded)\n",
    "print( \"F1 score and accuracy score for training set: {:.4f} , {:.4f}.\".format(f1 , acc))\n",
    "    \n",
    "f1, acc = predict_labels(clf, X_test, y_test_encoded)\n",
    "print(\"F1 score and accuracy score for test set: {:.4f} , {:.4f}.\".format(f1 , acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Save the model**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import joblib\n",
    "\n",
    "# Save the best XGBoost model using pickle\n",
    "with open('Models/best_xgboost_model.pkl', 'wb') as f:\n",
    "  pickle.dump(clf, f)\n",
    "\n",
    "# Alternative: Save using joblib (often better for scikit-learn models)\n",
    "joblib.dump(clf, 'Models/best_xgboost_model.joblib')\n",
    "\n",
    "# Also save the label encoder for future predictions\n",
    "joblib.dump(label_encoder, 'Models/label_encoder.joblib')\n",
    "\n",
    "print(\"Model and label encoder saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Import the Models amd Test**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the saved model and label encoder\n",
    "# Predicting with the saved model\n",
    "import joblib\n",
    "\n",
    "clf = joblib.load('Models/best_xgboost_model.joblib')\n",
    "label_encoder = joblib.load('Models/label_encoder.joblib')\n",
    "# Example input data for prediction\n",
    "example_input = X_test.iloc[0]  # Use the first row of the test set as an example\n",
    "example_input = example_input.values.reshape(1, -1)  # Reshape to match expected input shape\n",
    "\n",
    "# Making a prediction\n",
    "predicted_prob = clf.predict_proba(example_input)\n",
    "predicted_label = clf.predict(example_input)\n",
    "\n",
    "# Inverse transform the predicted label\n",
    "predicted_label = label_encoder.inverse_transform(predicted_label)\n",
    "\n",
    "print(\"Predicted probabilities:\", predicted_prob)\n",
    "print(\"Predicted label:\", predicted_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Load the Final Model and Test**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset columns:\n",
      "['Unnamed: 0', 'HTP', 'ATP', 'HM1_D', 'HM1_L', 'HM1_M', 'HM1_W', 'HM2_D', 'HM2_L', 'HM2_M', 'HM2_W', 'HM3_D', 'HM3_L', 'HM3_M', 'HM3_W', 'AM1_D', 'AM1_L', 'AM1_M', 'AM1_W', 'AM2_D', 'AM2_L', 'AM2_M', 'AM2_W', 'AM3_D', 'AM3_L', 'AM3_M', 'AM3_W', 'HTGD', 'ATGD', 'DiffFormPts', 'FTR']\n",
      "\n",
      "Test dataset shape: (7260, 31)\n",
      "\n",
      "First 5 rows of test dataset:\n",
      "   Unnamed: 0       HTP       ATP  HM1_D  HM1_L  HM1_M  HM1_W  HM2_D  HM2_L  \\\n",
      "0           0 -2.243556 -2.302919  False  False   True  False  False  False   \n",
      "1           1 -2.243556 -2.302919  False  False   True  False  False  False   \n",
      "2           2 -2.243556 -2.302919  False  False   True  False  False  False   \n",
      "3           3 -2.243556 -2.302919  False  False   True  False  False  False   \n",
      "4           4 -2.243556 -2.302919  False  False   True  False  False  False   \n",
      "\n",
      "   HM2_M  ...  AM2_M  AM2_W  AM3_D  AM3_L  AM3_M  AM3_W      HTGD      ATGD  \\\n",
      "0   True  ...   True  False  False  False   True  False  0.013859 -0.020465   \n",
      "1   True  ...   True  False  False  False   True  False  0.013859 -0.020465   \n",
      "2   True  ...   True  False  False  False   True  False  0.013859 -0.020465   \n",
      "3   True  ...   True  False  False  False   True  False  0.013859 -0.020465   \n",
      "4   True  ...   True  False  False  False   True  False  0.013859 -0.020465   \n",
      "\n",
      "   DiffFormPts  FTR  \n",
      "0          0.0    H  \n",
      "1          0.0    H  \n",
      "2          0.0   NH  \n",
      "3          0.0   NH  \n",
      "4          0.0    H  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "\n",
      "==================================================\n",
      "LOADING MODEL AND RUNNING PREDICTIONS\n",
      "==================================================\n",
      "Test features shape: (7260, 29)\n",
      "Test labels available: Yes (7260 samples)\n",
      "Features aligned with training data: (7260, 29)\n",
      "Available features: 29 out of 30 training features\n",
      "\n",
      "Predictions made: 7260 samples\n",
      "Prediction distribution:\n",
      "  H: 2678 predictions (36.9%)\n",
      "  NH: 4582 predictions (63.1%)\n",
      "\n",
      "Model Accuracy on test set: 0.6554 (65.54%)\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1768 1592]\n",
      " [ 910 2990]]\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           H       0.66      0.53      0.59      3360\n",
      "          NH       0.65      0.77      0.71      3900\n",
      "\n",
      "    accuracy                           0.66      7260\n",
      "   macro avg       0.66      0.65      0.65      7260\n",
      "weighted avg       0.66      0.66      0.65      7260\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Import the test dataset\n",
    "test_dataset = pd.read_csv(\"Self_Datasets/Final_Features_30_Features.csv\")\n",
    "\n",
    "# Display basic information about the test dataset\n",
    "print(\"Test dataset columns:\")\n",
    "print(test_dataset.columns.tolist())\n",
    "print(f\"\\nTest dataset shape: {test_dataset.shape}\")\n",
    "\n",
    "# Display first few rows to see the structure\n",
    "print(\"\\nFirst 5 rows of test dataset:\")\n",
    "print(test_dataset.head())\n",
    "\n",
    "# Load the saved model and label encoder\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"LOADING MODEL AND RUNNING PREDICTIONS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Prepare test data (assuming same preprocessing as training data)\n",
    "if 'FTR' in test_dataset.columns:\n",
    "  # Drop both FTR and Unnamed: 0 columns to match training data\n",
    "  columns_to_drop = ['FTR']\n",
    "  if 'Unnamed: 0' in test_dataset.columns:\n",
    "    columns_to_drop.append('Unnamed: 0')\n",
    "  \n",
    "  X_test_new = test_dataset.drop(columns=columns_to_drop)\n",
    "  y_test_new = test_dataset['FTR']\n",
    "  print(f\"Test features shape: {X_test_new.shape}\")\n",
    "  print(f\"Test labels available: Yes ({len(y_test_new)} samples)\")\n",
    "else:\n",
    "  # Drop Unnamed: 0 if it exists\n",
    "  columns_to_drop = []\n",
    "  if 'Unnamed: 0' in test_dataset.columns:\n",
    "    columns_to_drop.append('Unnamed: 0')\n",
    "  \n",
    "  X_test_new = test_dataset.drop(columns=columns_to_drop) if columns_to_drop else test_dataset.copy()\n",
    "  y_test_new = None\n",
    "  print(f\"Test features shape: {X_test_new.shape}\")\n",
    "  print(\"Test labels available: No\")\n",
    "\n",
    "# Ensure the feature order matches the training data\n",
    "# Get the original training feature names from the model\n",
    "training_features = clf.get_booster().feature_names\n",
    "# Filter out features that don't exist in X_test_new\n",
    "available_features = [feat for feat in training_features if feat in X_test_new.columns]\n",
    "X_test_new = X_test_new[available_features]\n",
    "print(f\"Features aligned with training data: {X_test_new.shape}\")\n",
    "print(f\"Available features: {len(available_features)} out of {len(training_features)} training features\")\n",
    "\n",
    "# Load the saved model and label encoder (ensure they are available)\n",
    "clf = joblib.load('Models/best_xgboost_model.joblib')\n",
    "label_encoder = joblib.load('Models/label_encoder.joblib')\n",
    "\n",
    "# Make predictions\n",
    "# Add the 'Unnamed: 0' column back to match training features\n",
    "X_test_new_with_unnamed = test_dataset[['Unnamed: 0'] + available_features].copy()\n",
    "\n",
    "# Make predictions with the complete feature set\n",
    "predictions = clf.predict(X_test_new_with_unnamed)\n",
    "prediction_probabilities = clf.predict_proba(X_test_new_with_unnamed)\n",
    "\n",
    "# Decode predictions back to original labels\n",
    "predictions_decoded = label_encoder.inverse_transform(predictions)\n",
    "\n",
    "# Display results\n",
    "print(f\"\\nPredictions made: {len(predictions)} samples\")\n",
    "print(f\"Prediction distribution:\")\n",
    "unique, counts = np.unique(predictions_decoded, return_counts=True)\n",
    "for label, count in zip(unique, counts):\n",
    "  print(f\"  {label}: {count} predictions ({count/len(predictions)*100:.1f}%)\")\n",
    "\n",
    "# If we have actual labels, calculate accuracy\n",
    "if y_test_new is not None:\n",
    "  # Encode actual labels for comparison\n",
    "  y_test_encoded = label_encoder.transform(y_test_new)\n",
    "  accuracy = (predictions == y_test_encoded).mean()\n",
    "  print(f\"\\nModel Accuracy on test set: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "  \n",
    "  # Show confusion matrix\n",
    "  cm_test = confusion_matrix(y_test_new, predictions_decoded)\n",
    "  print(f\"\\nConfusion Matrix:\")\n",
    "  print(cm_test)\n",
    "  \n",
    "  # Classification report\n",
    "  print(f\"\\nDetailed Classification Report:\")\n",
    "  print(classification_report(y_test_new, predictions_decoded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Prediction Interpretation\n",
    "\n",
    "The model has made a prediction for a specific football match with the following results:\n",
    "\n",
    "### **Predicted Probabilities:**\n",
    "\n",
    "- **Home Team Win (H): 35.55%**\n",
    "- **No Home Team Win (NH): 64.45%**\n",
    "\n",
    "### **Final Prediction: NH (No Home Team Win)**\n",
    "\n",
    "This means the model predicts that **the home team will NOT win** this particular match. The \"NH\" category includes both:\n",
    "\n",
    "- **Draw (D)**\n",
    "- **Away Team Win (A)**\n",
    "\n",
    "### **Confidence Level:**\n",
    "\n",
    "The model is **64.45% confident** that the home team will not win, while only **35.55% confident** that the home team will win.\n",
    "\n",
    "### **What This Means in Practice:**\n",
    "\n",
    "- The model suggests **betting against the home team** would be the safer choice\n",
    "- There's a **higher probability** of either a draw or away team victory\n",
    "- The prediction shows **moderate confidence** (not extremely high, but clear preference)\n",
    "\n",
    "### **Important Notes:**\n",
    "\n",
    "- This is a **binary classification** model (Home Win vs. No Home Win)\n",
    "- It doesn't distinguish between draws and away wins - both are classified as \"NH\"\n",
    "- The actual match outcome could still be a home win despite the prediction\n",
    "- Model accuracy is around **60-65%** based on the earlier results, so predictions aren't guaranteed\n",
    "\n",
    "**In simple terms: The model predicts the home team is more likely to lose or draw than to win this match.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probably little best!!!!!!!!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is not soo good but it can improved.\n",
    "\n",
    "Actually it only depend upon past year match dataset,we can improve the accuracy by putting twitter data related to match, sentiment analysis, chances of player to play a specific match,player performace in recent series,etc..\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I hope you find this kernel useful and enjoyable. If so please upVote\n",
    "\n",
    "Your comments and feedback are most welcome.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
